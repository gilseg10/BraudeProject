{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XYdXsZEqdyU"
      },
      "source": [
        "Install numpy, torch and other python libraries\n",
        "\n",
        "Install all the torch extended libraries with the recent TORCH and CUDA versions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y38ZJDkifP31",
        "outputId": "6715ea16-3a99-48fb-8159-e05507995a80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.12.1+cu102\n",
            "  Downloading https://download.pytorch.org/whl/cu102/torch-1.12.1%2Bcu102-cp310-cp310-linux_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.12.1+cu102) (4.12.2)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.1+cu121\n",
            "    Uninstalling torch-2.4.1+cu121:\n",
            "      Successfully uninstalled torch-2.4.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 1.12.1+cu102 which is incompatible.\n",
            "torchvision 0.19.1+cu121 requires torch==2.4.1, but you have torch 1.12.1+cu102 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.12.1+cu102\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.12.1+cu102.html\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp310-cp310-linux_x86_64.whl size=301091 sha256=f7ab903f9207c537cfc3a0c263408c14b1189f3a7ee3ef6e669f4386e704e3ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/f1/2b/3b46d54b134259f58c8363568569053248040859b1a145b3ce\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.12.1+cu102.html\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp310-cp310-linux_x86_64.whl size=544360 sha256=899b669282eeb788290f543b437a6953170eec7758fda7fac0172c8395e56a62\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/dd/0f/a6a16f9f3b0236733d257b4b4ea91b548b984a341ed3b8f38c\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.12.1+cu102.html\n",
            "Collecting torch-cluster\n",
            "  Downloading torch_cluster-1.6.3.tar.gz (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.26.4)\n",
            "Building wheels for collected packages: torch-cluster\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-cluster: filename=torch_cluster-1.6.3-cp310-cp310-linux_x86_64.whl size=286704 sha256=aaa7748da232e74f4a048dce2d2aa54ba7dfc77a8298e440a8b5df2839143b2b\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/78/c3/536637b3cdcc3313aa5e8851a6c72b97f6a01877e68c7595e3\n",
            "Successfully built torch-cluster\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.12.1+cu102.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading torch_spline_conv-1.2.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-spline-conv\n",
            "  Building wheel for torch-spline-conv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-spline-conv: filename=torch_spline_conv-1.2.2-cp310-cp310-linux_x86_64.whl size=109891 sha256=12d405108f8d77b7cdcea5e0a8e0d01928273f8748c9da644c01458a532eaed2\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/34/be/187e4b5f5ccefecca2c1a5dfc8da244ec50baa1f33c7b8c9a1\n",
            "Successfully built torch-spline-conv\n",
            "Installing collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.2\n",
            "Collecting torch-geometric==2.5.3\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.5.3) (4.66.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.5.3) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.5.3) (1.13.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.5.3) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.5.3) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.5.3) (3.10.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.5.3) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.5.3) (3.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.5.3) (1.3.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.5.3) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.5.3) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.5.3) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.5.3) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.5.3) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.5.3) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.5.3) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.5.3) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.5.3) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.5.3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.5.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.5.3) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.5.3) (2024.8.30)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.5.3) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.5.3) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric==2.5.3) (4.12.2)\n",
            "Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.5.3\n",
            "Collecting texttable==1.6.2\n",
            "  Downloading texttable-1.6.2-py2.py3-none-any.whl.metadata (9.5 kB)\n",
            "Downloading texttable-1.6.2-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: texttable\n",
            "Successfully installed texttable-1.6.2\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy>=1.22\n",
        "!pip install torch==1.12.1+cu102 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install pandas\n",
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric==2.5.3\n",
        "!pip install texttable==1.6.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWT71EO1qu2y"
      },
      "source": [
        "Cloning from git the reposetories and to enter the folder\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "B4PuXU-AxeV8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01f7b432-2677-4551-9246-8ba9fffcce80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/BraudeProject'...\n",
            "remote: Enumerating objects: 160, done.\u001b[K\n",
            "remote: Counting objects: 100% (160/160), done.\u001b[K\n",
            "remote: Compressing objects: 100% (109/109), done.\u001b[K\n",
            "remote: Total 160 (delta 96), reused 96 (delta 49), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (160/160), 8.43 MiB | 12.44 MiB/s, done.\n",
            "Resolving deltas: 100% (96/96), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone the GitHub repository\n",
        "!git clone https://github.com/gilseg10/BraudeProject.git /content/BraudeProject\n",
        "# !git pull https://github.com/gilseg10/BraudeProject.git\n",
        "# Change the current working directory to the cloned repository\n",
        "import os\n",
        "os.chdir(\"/content/BraudeProject/MaskGAE_code\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Examples for running the train_linkpred.py with different parameters\n",
        "\n",
        "List of parameters:\n",
        "\n",
        "\"--dataset\" - set the dataset (default: Cora)\n",
        "\n",
        "\"--mask\" - set the Masking strategy, `Path`, `Edge` or `None` (default: Path)\n",
        "\n",
        "\"--seed\" - set seed for model and dataset (default: 2022)\n",
        "\n",
        "\"--bn\" - set whether to use batch normalization for GNN encoder (default: False)\n",
        "\n",
        "\"--layer\" - set type of GNN layer (default: gcn)\n",
        "\n",
        "\"--encoder_activation\" - set activation function for GNN encoder (default: elu)\n",
        "\n",
        "\"--encoder_channels\" - set number of channels of GNN encoder (default: 128)\n",
        "\n",
        "\"--hidden_channels\" - set number of channels of hidden representation (default: 128)\n",
        "\n",
        "\"--decoder_channels\" - set number of channels of decoder (default: 64)\n",
        "\n",
        "\"--encoder_layers\" - set number of layers of encoder (default: 1)\n",
        "\n",
        "\"--decoder_layers\" - set number of layers for decoders (default: 2)\n",
        "\n",
        "\"--encoder_dropout\" - set dropout probability of encoder (default: 0.7)\n",
        "\n",
        "\"--decoder_dropout\" - set dropout probability of decoder (default: 0.3)\n",
        "\n",
        "\"--alpha\" - set loss weight for degree prediction (default: 0.003)\n",
        "\n",
        "\"--lr\" - set learning rate for training (default: 0.001)\n",
        "\n",
        "\"--weight_decay\" - set weight_decay for training (default: 5e-5)\n",
        "\n",
        "\"--grad_norm\" - set grad_norm for training (default: 1.0)\n",
        "\n",
        "\"--batch_size\" - set number of batch size (default: 2**16)\n",
        "\n",
        "\"--start\" - set which type to sample starting nodes for random walks (default: edge)\n",
        "\n",
        "\"--p\" - set mask ratio or sample ratio for MaskEdge MaskPath (default: 0.7)\n",
        "\n",
        "\"--epochs\" - set number of training epochs (default: 300)\n",
        "\n",
        "\"--runs\" - set number of runs (default: 10)\n",
        "\n",
        "\"--eval_period\" - set evaluation period (default: 10)\n",
        "\n",
        "\"--save_path\" - set path for model (default=\"MaskGAE-LinkPred.pt\")parser.\n",
        "\n",
        "\"--device\" - set device (default=0)"
      ],
      "metadata": {
        "id": "Kbp7Q4n8DoA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_linkpred.py --dataset Cora --bn --encoder_dropout 0.2 --runs 30\n",
        "!rm link_statistics.csv # remove the created .csv file\n",
        "!python train_linkpred.py --dataset Cora --bn --encoder_dropout 0.2 --mask Edge --runs 30\n",
        "!rm link_statistics.csv # remove the created .csv file"
      ],
      "metadata": {
        "id": "fNpXOS0eGN56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_linkpred.py --dataset Cora --bn --runs 30\n",
        "!rm link_statistics.csv # remove the created .csv file\n",
        "!python train_linkpred.py --dataset Cora --bn --mask Edge --runs 30\n",
        "!rm link_statistics.csv # remove the created .csv file"
      ],
      "metadata": {
        "id": "uC8ArMAf4rL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"output 5 - 30% test_set with alpha=0.0001\"\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 30 --alpha 0.0001\n",
        "!rm link_statistics.csv # remove the created .csv file\n",
        "!python train_linkpred.py --dataset Cora --bn --mask Edge --runs 30 --alpha 0.0001\n",
        "!rm link_statistics.csv # remove the created .csv file"
      ],
      "metadata": {
        "id": "JQ6yVJ8pz1Cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"output 6 - 30% test_set with encoder_dropout 0.5\"\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 30 --encoder_dropout 0.5\n",
        "!rm link_statistics.csv # remove the created .csv file\n",
        "!python train_linkpred.py --dataset Cora --bn --mask Edge --runs 30 --encoder_dropout 0.5\n",
        "!rm link_statistics.csv # remove the created .csv file"
      ],
      "metadata": {
        "id": "B_KzUmEOqlPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"output 7 - 30% test_set with decoder_dropout 0.8\"\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 30 --decoder_dropout 0.8\n",
        "!rm link_statistics.csv # remove the created .csv file\n",
        "!python train_linkpred.py --dataset Cora --bn --mask Edge --runs 30 --decoder_dropout 0.8\n",
        "!rm link_statistics.csv # remove the created .csv file"
      ],
      "metadata": {
        "id": "EKXCRMcfG8Dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"output 8 - 50% test_set with 0.2 encoder_dropout\"\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 30 --encoder_dropout 0.2\n",
        "!rm link_statistics.csv # remove the created .csv file\n",
        "!python train_linkpred.py --dataset Cora --bn --mask Edge --runs 30 --encoder_dropout 0.2\n",
        "!rm link_statistics.csv # remove the created .csv file"
      ],
      "metadata": {
        "id": "q6293KSVX2oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"output 9 - 50% test_set with 0.8 encoder_dropout\"\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 30 --encoder_dropout 0.8\n",
        "!rm link_statistics.csv # remove the created .csv file\n",
        "!python train_linkpred.py --dataset Cora --bn --mask Edge --runs 30 --encoder_dropout 0.8\n",
        "!rm link_statistics.csv # remove the created .csv file"
      ],
      "metadata": {
        "id": "uu6I-IuPqNN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example of creating link prediction statistics\n",
        "\n",
        "We use the Cora data set and set the `run` parameter to 1 with random seed to create a random test set for each run. In this example there is total of 40 runs where all parameters are with default values."
      ],
      "metadata": {
        "id": "Ptb6AIqqHumG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM\n"
      ],
      "metadata": {
        "id": "EG6S2DqNBaZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!python train_linkpred.py --dataset Cora --bn --runs 1 --seed $RANDOM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztcPmB9xR-2L",
        "outputId": "bd3febaf-71c1-4bd4-fa9b-71c83aa4972a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------------------+\n",
            "|     Parameter      |        Value        |\n",
            "+====================+=====================+\n",
            "| alpha              | 0.003               |\n",
            "+--------------------+---------------------+\n",
            "| batch_size         | 65536               |\n",
            "+--------------------+---------------------+\n",
            "| bn                 | True                |\n",
            "+--------------------+---------------------+\n",
            "| dataset            | Cora                |\n",
            "+--------------------+---------------------+\n",
            "| decoder_channels   | 64                  |\n",
            "+--------------------+---------------------+\n",
            "| decoder_dropout    | 0.200               |\n",
            "+--------------------+---------------------+\n",
            "| decoder_layers     | 2                   |\n",
            "+--------------------+---------------------+\n",
            "| device             | 0                   |\n",
            "+--------------------+---------------------+\n",
            "| encoder_activation | elu                 |\n",
            "+--------------------+---------------------+\n",
            "| encoder_channels   | 128                 |\n",
            "+--------------------+---------------------+\n",
            "| encoder_dropout    | 0.800               |\n",
            "+--------------------+---------------------+\n",
            "| encoder_layers     | 1                   |\n",
            "+--------------------+---------------------+\n",
            "| epochs             | 500                 |\n",
            "+--------------------+---------------------+\n",
            "| eval_period        | 10                  |\n",
            "+--------------------+---------------------+\n",
            "| grad_norm          | 1                   |\n",
            "+--------------------+---------------------+\n",
            "| hidden_channels    | 128                 |\n",
            "+--------------------+---------------------+\n",
            "| layer              | gcn                 |\n",
            "+--------------------+---------------------+\n",
            "| lr                 | 0.010               |\n",
            "+--------------------+---------------------+\n",
            "| mask               | Path                |\n",
            "+--------------------+---------------------+\n",
            "| p                  | 0.700               |\n",
            "+--------------------+---------------------+\n",
            "| runs               | 1                   |\n",
            "+--------------------+---------------------+\n",
            "| save_path          | MaskGAE-LinkPred.pt |\n",
            "+--------------------+---------------------+\n",
            "| seed               | 17015               |\n",
            "+--------------------+---------------------+\n",
            "| start              | edge                |\n",
            "+--------------------+---------------------+\n",
            "| weight_decay       | 0.000               |\n",
            "+--------------------+---------------------+\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n",
            "Initializing new statistics for all links.\n",
            "100% 500/500 [01:05<00:00,  7.65it/s]\n",
            "Run 1 completed and statistics updated.\n",
            "Statistics saved to link_statistics.csv\n",
            "Run 1 - AUC: 96.21%, AP: 96.44%, Correct Predictions: 2657, Restored Links: 1536\n",
            "Link Prediction Results (1 runs):\n",
            "AUC: 96.21% ± 0.00% AP: 96.44% ± 0.00% Correct Predictions: 2657.0 ± 0.0 Restored Links: 1536.0 ± 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After previous cell, a .csv file will be created under the name \"link_statistics.csv\" and you can use it to build an histogram showing the distribution of correct predictions for each link."
      ],
      "metadata": {
        "id": "e9Eq2RGgMCb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a limit for the x-axis (number of times the edge was correctly predicted)\n",
        "x_limit = 30\n",
        "\n",
        "# Load the statistics file\n",
        "statistics_df = pd.read_csv('link_statistics.csv')\n",
        "\n",
        "# Filter the data to include only edges where 'correctly_predicted' is between 0 and the x_limit\n",
        "filtered_df = statistics_df[statistics_df['correctly_predicted'].between(0, x_limit)]\n",
        "\n",
        "# Plot the histogram of correctly_predicted values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(filtered_df['correctly_predicted'], bins=range(0, 31), alpha=0.7, color='b', edgecolor='black')\n",
        "\n",
        "# Set axis labels and title\n",
        "plt.xlabel('Correctly Predicted Count')\n",
        "plt.ylabel('Number of Links')\n",
        "plt.title('Distribution of Correctly Predicted Links')\n",
        "\n",
        "# Set x-axis limits\n",
        "plt.xlim(0, 30)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JtHg3OFCnIUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can later delete the .csv file if you want to run the link prediction script with different values for the parameters."
      ],
      "metadata": {
        "id": "uRvuwdRIMkTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm link_statistics.csv\n",
        "!ls"
      ],
      "metadata": {
        "id": "IDkxrQPip_iq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfa29a9b-dc9c-438b-97a7-b61d639f9afa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  maskgae  MaskGAE-LinkPred.pt  train_linkpred_ogb.py  train_linkpred.py  train_nodeclas.py\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}